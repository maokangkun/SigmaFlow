{
    "OpenAIModel": {
        "input": {
            "required": {
                "base_url": ["STRING", {}],
                "api_key": ["STRING", {}],
                "model": [
                    "STRING",
                    {
                        "tooltip": "The name of the model.",
                        "default": "gpt-5"
                    }
                ],
                "max_completion_tokens": [
                    "INT",
                    {
                        "default": 2048,
                        "min": 1,
                        "max": 10000000,
                        "tooltip": "Use the max_completion_tokens parameter to limit how many tokens the model will generate."
                    }
                ],
                "temperature": [
                    "FLOAT",
                    {
                        "default": 1.0,
                        "min": 0.0,
                        "max": 2.0,
                        "step": 0.1,
                        "tooltip": "The temperature parameter determines the creativity or predictability of each response."
                    }
                ],
                "tracing": [
                    "BOOLEAN",
                    {
                        "tooltip": "Whether to enable tracing for this workflow. Tracing allows you to see the details of the API call in the execution trace, which can be useful for debugging and analysis.",
                        "default": true
                    }
                ],
                "trace_key": ["STRING", {}]
            }
        },
        "input_order": {
            "required": [
                "base_url",
                "api_key",
                "model",
                "max_completion_tokens",
                "temperature",
                "tracing",
                "trace_key"
            ]
        },
        "output": [
            "MODEL"
        ],
        "output_is_list": [
            false
        ],
        "output_name": [
            "MODEL"
        ],
        "name": "OpenAIModel",
        "display_name": "OpenAI Model",
        "description": "Using a OpenAI LLM model api.",
        "python_module": "nodes",
        "category": "sigmaflow/model",
        "output_node": false,
        "output_tooltips": [
            "The model used for LLM node."
        ],
        "ui": {
            "color_name": "blue",
            "shape": "box"
        }
    },
    "LoadJSON": {
        "input": {
            "required": {
                "data": [
                    [
                        "example.json"
                    ],
                    {
                        "file_upload": true
                    }
                ]
            }
        },
        "input_order": {
            "required": [
                "data"
            ]
        },
        "output": [
            "IMAGE"
        ],
        "output_is_list": [
            false
        ],
        "output_name": [
            "IMAGE"
        ],
        "name": "LoadJSON",
        "display_name": "Load JSON",
        "description": "",
        "python_module": "nodes",
        "category": "sigmaflow/data",
        "output_node": false
    },
    "LoadImage": {
        "input": {
            "required": {
                "image": [
                    [
                        "example.png"
                    ],
                    {
                        "image_upload": true
                    }
                ]
            }
        },
        "input_order": {
            "required": [
                "image"
            ]
        },
        "output": [
            "IMAGE"
        ],
        "output_is_list": [
            false
        ],
        "output_name": [
            "IMAGE"
        ],
        "name": "LoadImage",
        "display_name": "Load Image",
        "description": "",
        "python_module": "nodes",
        "category": "sigmaflow/data",
        "output_node": false
    },
    "JSONData": {
        "input": {
            "required": {
                "json": [
                    "STRING",
                    {
                        "multiline": true,
                        "tooltip": "The JSON data as input."
                    }
                ]
            }
        },
        "input_order": {
            "required": [
                "json"
            ]
        },
        "output": [
            "STRING"
        ],
        "output_is_list": [
            false
        ],
        "output_name": [
            "data"
        ],
        "name": "JSONData",
        "display_name": "JSON Data",
        "description": "JSON data as input.",
        "python_module": "nodes",
        "category": "sigmaflow/data",
        "output_node": false,
        "output_tooltips": [],
        "ui": {
            "color_name": "red",
            "shape": "box"
        }
    },
    "LLMNode": {
        "input": {
            "required": {
                "prompt": [
                    "STRING",
                    {
                        "tooltip": "Text inputs to the model, used to generate a response.",
                        "default": "",
                        "multiline": true
                    }
                ],
                "return_json": [
                    "BOOLEAN",
                    {
                        "tooltip": "Make sure returned in JSON format",
                        "default": false
                    }
                ],
                "format": [
                    "STRING",
                    {
                        "tooltip": "(Optional) Ensures output data matches a specified type or structure (e.g., int, float, list, dict). This is used when `return_json` is True.",
                        "default": ""
                    }
                ],
                "remove_think": [
                    "BOOLEAN",
                    {
                        "tooltip": "Remove '<think>...</think>' from the response",
                        "default": true
                    }
                ],
                "out": [
                    "STRING",
                    {
                        "tooltip": "Ensures output renames to specific name.",
                        "default": ""
                    }
                ]
            },
            "optional": {
                "model": [
                    "MODEL",
                    {
                        "tooltip": "The model used to generate the response"
                    }
                ],
                "condition": ["*"]
            },
            "hidden": {}
        },
        "input_order": {
            "required": [
                "prompt",
                "return_json",
                "format",
                "remove_think",
                "out"
            ],
            "optional": [
                "model",
                "condition"
            ],
            "hidden": []
        },
        "output": [
            "STRING"
        ],
        "output_is_list": [
            false
        ],
        "output_name": [
            "out"
        ],
        "output_tooltips": [
            null
        ],
        "name": "LLMNode",
        "display_name": "LLM Node",
        "description": "Generate text responses from an LLM model.",
        "python_module": "comfy_api_nodes.nodes_openai",
        "category": "sigmaflow",
        "output_node": true,
        "api_node": true
    },
    "LoopNode": {
        "input": {
            "required": {
                "items": [
                    "*",
                    {
                        "tooltip": ""
                    }
                ],
                "node_in_loop": []
            },
            "optional": {},
            "hidden": {}
        },
        "input_order": {
            "required": [
                "items",
                "node_in_loop"
            ],
            "optional": [],
            "hidden": []
        },
        "output": [],
        "output_is_list": [
            false
        ],
        "output_name": [],
        "output_tooltips": [
            null
        ],
        "name": "LoopNode",
        "display_name": "Loop Node",
        "description": "",
        "python_module": "nodes",
        "category": "sigmaflow",
        "output_node": false,
        "ui": {
            "color_name": "cyan",
            "shape": "box"
        }
    },
    "BranchNode": {
        "input": {
            "required": {
                "inp": [
                    "*",
                    {
                        "tooltip": ""
                    }
                ],
                "use_llm": [
                    "BOOLEAN",
                    {
                        "tooltip": "Using LLM to decide the branch",
                        "default": true
                    }
                ],
                "code": [
                    "STRING",
                    {
                        "tooltip": "Using code to decide the branch. The variable 'inp' is the input data. The code should return a item indicating the next branch.",
                        "default": "",
                        "multiline": true
                    }
                ]
            },
            "optional": {},
            "hidden": {}
        },
        "input_order": {
            "required": [
                "inp",
                "use_llm",
                "code"
            ],
            "optional": [],
            "hidden": []
        },
        "output": [],
        "output_is_list": [
            false
        ],
        "output_name": [],
        "output_tooltips": [
            null
        ],
        "name": "BranchNode",
        "display_name": "Branch Node",
        "description": "",
        "python_module": "nodes",
        "category": "sigmaflow",
        "output_node": false,
        "ui": {
            "color_name": "pale_blue"
        }
    },
    "CodeNode": {
        "input": {
            "required": {
                "inp": [
                    "*",
                    {
                        "tooltip": ""
                    }
                ],
                "code": [
                    "STRING",
                    {
                        "tooltip": "Excute custom code. The variable 'inp' is the input data. The code should return the output data.",
                        "default": "",
                        "multiline": true
                    }
                ],
                "out": [
                    "STRING",
                    {
                        "tooltip": "Ensures output renames to specific name.",
                        "default": ""
                    }
                ]
            },
            "optional": {},
            "hidden": {}
        },
        "input_order": {
            "required": [
                "inp",
                "code",
                "out"
            ],
            "optional": [],
            "hidden": []
        },
        "output": [
            "*"
        ],
        "output_is_list": [
            false
        ],
        "output_name": [
            "out"
        ],
        "output_tooltips": [
            null
        ],
        "name": "CodeNode",
        "display_name": "Code Node",
        "description": "",
        "python_module": "nodes",
        "category": "sigmaflow",
        "output_node": false,
        "ui": {
            "color_name": "green"
        }
    }
}